---
title: Latest 15 Papers - November 20, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## data synthesis
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ARC Is a Vision Problem!](https://arxiv.org/abs/2511.14761v1)** | 2025-11-18 | <details><summary>Techn...</summary><p>Technical Report. Project webpage: https://github.com/lillian039/VARC</p></details> |
| **[$π^{*}_{0.6}$: a VLA That Learns From Experience](https://arxiv.org/abs/2511.14759v1)** | 2025-11-18 |  |
| **[Sim-to-real supervised domain adaptation for radioisotope identification](https://arxiv.org/abs/2412.07069v4)** | 2025-11-18 | <details><summary>32 pa...</summary><p>32 pages, 9 figures, and 7 tables</p></details> |
| **[HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation](https://arxiv.org/abs/2511.14756v1)** | 2025-11-18 |  |
| **[SparseST: Exploiting Data Sparsity in Spatiotemporal Modeling and Prediction](https://arxiv.org/abs/2511.14753v1)** | 2025-11-18 |  |
| **[Vision Large Language Models Are Good Noise Handlers in Engagement Analysis](https://arxiv.org/abs/2511.14749v1)** | 2025-11-18 |  |
| **[Cloud-Native Vector Search: A Comprehensive Performance Analysis](https://arxiv.org/abs/2511.14748v1)** | 2025-11-18 |  |

## data selection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ARC Is a Vision Problem!](https://arxiv.org/abs/2511.14761v1)** | 2025-11-18 | <details><summary>Techn...</summary><p>Technical Report. Project webpage: https://github.com/lillian039/VARC</p></details> |
| **[$π^{*}_{0.6}$: a VLA That Learns From Experience](https://arxiv.org/abs/2511.14759v1)** | 2025-11-18 |  |
| **[Sim-to-real supervised domain adaptation for radioisotope identification](https://arxiv.org/abs/2412.07069v4)** | 2025-11-18 | <details><summary>32 pa...</summary><p>32 pages, 9 figures, and 7 tables</p></details> |
| **[HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation](https://arxiv.org/abs/2511.14756v1)** | 2025-11-18 |  |
| **[SparseST: Exploiting Data Sparsity in Spatiotemporal Modeling and Prediction](https://arxiv.org/abs/2511.14753v1)** | 2025-11-18 |  |
| **[Co-Me: Confidence-Guided Token Merging for Visual Geometric Transformers](https://arxiv.org/abs/2511.14751v1)** | 2025-11-18 |  |
| **[Vision Large Language Models Are Good Noise Handlers in Engagement Analysis](https://arxiv.org/abs/2511.14749v1)** | 2025-11-18 |  |
| **[Cloud-Native Vector Search: A Comprehensive Performance Analysis](https://arxiv.org/abs/2511.14748v1)** | 2025-11-18 |  |

## MLLMs
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning](https://arxiv.org/abs/2511.14760v1)** | 2025-11-18 |  |
| **[MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999v2)** | 2025-11-18 | <details><summary>Accep...</summary><p>Accepted by WSDM 2026. 11 pages, 9 figures</p></details> |
| **[RynnEC: Bringing MLLMs into Embodied World](https://arxiv.org/abs/2508.14160v2)** | 2025-11-18 | <details><summary>The t...</summary><p>The technical report of RynnEC, an embodied cognition MLLM</p></details> |
| **[ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation](https://arxiv.org/abs/2511.14259v1)** | 2025-11-18 |  |
| **[EventHallusion: Diagnosing Event Hallucinations in Video LLMs](https://arxiv.org/abs/2409.16597v6)** | 2025-11-18 |  |
| **[MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions](https://arxiv.org/abs/2507.21503v2)** | 2025-11-18 | AAAI2026 Oral |
| **[Viper-F1: Fast and Fine-Grained Multimodal Understanding with Cross-Modal State-Space Modulation](https://arxiv.org/abs/2511.11177v3)** | 2025-11-18 | <details><summary>Need ...</summary><p>Need to enhance the method and benchmark to be better</p></details> |
| **[Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline](https://arxiv.org/abs/2511.13442v2)** | 2025-11-18 |  |
| **[AdaTok: Adaptive Token Compression with Object-Aware Representations for Efficient Multimodal LLMs](https://arxiv.org/abs/2511.14169v1)** | 2025-11-18 |  |
| **[From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models](https://arxiv.org/abs/2511.12861v2)** | 2025-11-18 | <details><summary>Surve...</summary><p>Survey; 7 figures, 3 tables, 44 pages</p></details> |

## data curation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ARC Is a Vision Problem!](https://arxiv.org/abs/2511.14761v1)** | 2025-11-18 | <details><summary>Techn...</summary><p>Technical Report. Project webpage: https://github.com/lillian039/VARC</p></details> |
| **[$π^{*}_{0.6}$: a VLA That Learns From Experience](https://arxiv.org/abs/2511.14759v1)** | 2025-11-18 |  |
| **[Sim-to-real supervised domain adaptation for radioisotope identification](https://arxiv.org/abs/2412.07069v4)** | 2025-11-18 | <details><summary>32 pa...</summary><p>32 pages, 9 figures, and 7 tables</p></details> |
| **[HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation](https://arxiv.org/abs/2511.14756v1)** | 2025-11-18 |  |
| **[SparseST: Exploiting Data Sparsity in Spatiotemporal Modeling and Prediction](https://arxiv.org/abs/2511.14753v1)** | 2025-11-18 |  |
| **[Vision Large Language Models Are Good Noise Handlers in Engagement Analysis](https://arxiv.org/abs/2511.14749v1)** | 2025-11-18 |  |
| **[Cloud-Native Vector Search: A Comprehensive Performance Analysis](https://arxiv.org/abs/2511.14748v1)** | 2025-11-18 |  |

