---
title: Latest 15 Papers - January 22, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## data synthesis
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255v1)** | 2026-01-20 | <details><summary>Proje...</summary><p>Project page: https://cvlab-kaist.github.io/VideoMaMa/</p></details> |
| **[Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253v1)** | 2026-01-20 | <details><summary>Proje...</summary><p>Project page: https://motion3-to-4.github.io/. Code: https://github.com/Inception3D/Motion324</p></details> |
| **[Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249v1)** | 2026-01-20 | <details><summary>26 pa...</summary><p>26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio</p></details> |
| **[Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration](https://arxiv.org/abs/2601.14235v1)** | 2026-01-20 | <details><summary>84 pa...</summary><p>84 pages. This is v1.0 of the DESC's white paper on AI/ML, a collaboration document that is being made public but which is not planned for submission to a journal</p></details> |
| **[Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228v1)** | 2026-01-20 | <details><summary>8 pag...</summary><p>8 pages, 6 figures, Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/</p></details> |
| **[Deep Learning Approaches to Quantum Error Mitigation](https://arxiv.org/abs/2601.14226v1)** | 2026-01-20 | 48 pages |

## data selection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255v1)** | 2026-01-20 | <details><summary>Proje...</summary><p>Project page: https://cvlab-kaist.github.io/VideoMaMa/</p></details> |
| **[Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253v1)** | 2026-01-20 | <details><summary>Proje...</summary><p>Project page: https://motion3-to-4.github.io/. Code: https://github.com/Inception3D/Motion324</p></details> |
| **[Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249v1)** | 2026-01-20 | <details><summary>26 pa...</summary><p>26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio</p></details> |
| **[Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration](https://arxiv.org/abs/2601.14235v1)** | 2026-01-20 | <details><summary>84 pa...</summary><p>84 pages. This is v1.0 of the DESC's white paper on AI/ML, a collaboration document that is being made public but which is not planned for submission to a journal</p></details> |
| **[Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228v1)** | 2026-01-20 | <details><summary>8 pag...</summary><p>8 pages, 6 figures, Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/</p></details> |
| **[Deep Learning Approaches to Quantum Error Mitigation](https://arxiv.org/abs/2601.14226v1)** | 2026-01-20 | 48 pages |

## MLLMs
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127v1)** | 2026-01-20 | <details><summary>*15 p...</summary><p>*15 pages, 5 figures. Introduces MIR-SafetyBench (2,676 instances; 9 multi-image relations). Equal contribution; â€ Corresponding author. Code/data: https://github.com/thu-coai/MIR-SafetyBench</p></details> |
| **[Hummus: A Dataset of Humorous Multimodal Metaphor Use](https://arxiv.org/abs/2504.02983v2)** | 2026-01-20 |  |
| **[Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052v1)** | 2026-01-20 |  |
| **[Chain-of-Thought Compression Should Not Be Blind: V-Skip for Efficient Multimodal Reasoning via Dual-Path Anchoring](https://arxiv.org/abs/2601.13879v1)** | 2026-01-20 |  |
| **[Question-Focused Filtering for Knowledge-based VQA](https://arxiv.org/abs/2601.13856v1)** | 2026-01-20 |  |
| **[FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs](https://arxiv.org/abs/2601.13836v1)** | 2026-01-20 | <details><summary>https...</summary><p>https://openmoss.github.io/FutureOmni</p></details> |
| **[RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature](https://arxiv.org/abs/2512.23565v4)** | 2026-01-20 |  |
| **[Hierarchy-Aware Multimodal Unlearning for Medical AI](https://arxiv.org/abs/2512.09867v2)** | 2026-01-20 | <details><summary>Datas...</summary><p>Dataset and Code: https://github.com/fengli-wu/MedForget</p></details> |
| **[ELO: Efficient Layer-Specific Optimization for Continual Pretraining of Multilingual LLMs](https://arxiv.org/abs/2601.03648v2)** | 2026-01-20 | <details><summary>12 pa...</summary><p>12 pages, Accepted to EACL 2026 (Industrial Track)</p></details> |
| **[DomainCQA: Crafting Knowledge-Intensive QA from Domain-Specific Charts](https://arxiv.org/abs/2503.19498v6)** | 2026-01-20 | 83 pages, 59 figures |

## data curation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255v1)** | 2026-01-20 | <details><summary>Proje...</summary><p>Project page: https://cvlab-kaist.github.io/VideoMaMa/</p></details> |
| **[Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253v1)** | 2026-01-20 | <details><summary>Proje...</summary><p>Project page: https://motion3-to-4.github.io/. Code: https://github.com/Inception3D/Motion324</p></details> |
| **[Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249v1)** | 2026-01-20 | <details><summary>26 pa...</summary><p>26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio</p></details> |
| **[Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration](https://arxiv.org/abs/2601.14235v1)** | 2026-01-20 | <details><summary>84 pa...</summary><p>84 pages. This is v1.0 of the DESC's white paper on AI/ML, a collaboration document that is being made public but which is not planned for submission to a journal</p></details> |
| **[Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment](https://arxiv.org/abs/2601.14228v1)** | 2026-01-20 | <details><summary>8 pag...</summary><p>8 pages, 6 figures, Conference: IEEE International Conference on Machine Learning and Applications 2025 (ICMLA 2025): https://www.icmla-conference.org/icmla25/</p></details> |
| **[Deep Learning Approaches to Quantum Error Mitigation](https://arxiv.org/abs/2601.14226v1)** | 2026-01-20 | 48 pages |

