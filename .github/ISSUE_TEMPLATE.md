---
title: Latest 15 Papers - February 19, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## data synthesis
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution](https://arxiv.org/abs/2602.15830v1)** | 2026-02-17 |  |
| **[Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828v1)** | 2026-02-17 | <details><summary>Proje...</summary><p>Project page: https://dex4d.github.io/</p></details> |
| **[Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence](https://arxiv.org/abs/2602.15019v2)** | 2026-02-17 |  |
| **[stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation](https://arxiv.org/abs/2602.08968v2)** | 2026-02-17 |  |
| **[Computation and Size of Interpolants for Hybrid Modal Logics](https://arxiv.org/abs/2602.15821v1)** | 2026-02-17 |  |
| **[VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819v1)** | 2026-02-17 |  |
| **[Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816v1)** | 2026-02-17 |  |
| **[Task-Agnostic Continual Learning for Chest Radiograph Classification](https://arxiv.org/abs/2602.15811v1)** | 2026-02-17 | 12 pages, 3 figures |

## data selection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution](https://arxiv.org/abs/2602.15830v1)** | 2026-02-17 |  |
| **[Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828v1)** | 2026-02-17 | <details><summary>Proje...</summary><p>Project page: https://dex4d.github.io/</p></details> |
| **[Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching](https://arxiv.org/abs/2602.15827v1)** | 2026-02-17 |  |
| **[Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence](https://arxiv.org/abs/2602.15019v2)** | 2026-02-17 |  |
| **[stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation](https://arxiv.org/abs/2602.08968v2)** | 2026-02-17 |  |
| **[Computation and Size of Interpolants for Hybrid Modal Logics](https://arxiv.org/abs/2602.15821v1)** | 2026-02-17 |  |
| **[Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics](https://arxiv.org/abs/2602.15820v1)** | 2026-02-17 |  |
| **[VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819v1)** | 2026-02-17 |  |
| **[Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816v1)** | 2026-02-17 |  |

## MLLMs
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769v1)** | 2026-02-17 |  |
| **[ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758v1)** | 2026-02-17 | <details><summary>16 pa...</summary><p>16 pages, 13 figures including Supplementary Material</p></details> |
| **[Can Multimodal LLMs Perform Time Series Anomaly Detection?](https://arxiv.org/abs/2502.17812v2)** | 2026-02-17 | <details><summary>ACM W...</summary><p>ACM Web Conference 2026 (WWW'26)</p></details> |
| **[Text-Guided Layer Fusion Mitigates Hallucination in Multimodal LLMs](https://arxiv.org/abs/2601.03100v2)** | 2026-02-17 |  |
| **[Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling](https://arxiv.org/abs/2602.15513v1)** | 2026-02-17 |  |
| **[Emergent Morphing Attack Detection in Open Multi-modal Large Language Models](https://arxiv.org/abs/2602.15461v1)** | 2026-02-17 | <details><summary>This ...</summary><p>This manuscript is currently under review at Pattern Recognition Letters</p></details> |
| **[One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation](https://arxiv.org/abs/2602.15400v1)** | 2026-02-17 |  |
| **[EventMemAgent: Hierarchical Event-Centric Memory for Online Video Understanding with Adaptive Tool Use](https://arxiv.org/abs/2602.15329v1)** | 2026-02-17 |  |
| **[Zero-shot HOI Detection with MLLM-based Detector-agnostic Interaction Recognition](https://arxiv.org/abs/2602.15124v1)** | 2026-02-16 | ICLR 2026 |
| **[Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception](https://arxiv.org/abs/2602.11858v2)** | 2026-02-16 |  |

## data curation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution](https://arxiv.org/abs/2602.15830v1)** | 2026-02-17 |  |
| **[Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation](https://arxiv.org/abs/2602.15828v1)** | 2026-02-17 | <details><summary>Proje...</summary><p>Project page: https://dex4d.github.io/</p></details> |
| **[Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence](https://arxiv.org/abs/2602.15019v2)** | 2026-02-17 |  |
| **[stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation](https://arxiv.org/abs/2602.08968v2)** | 2026-02-17 |  |
| **[Computation and Size of Interpolants for Hybrid Modal Logics](https://arxiv.org/abs/2602.15821v1)** | 2026-02-17 |  |
| **[VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation](https://arxiv.org/abs/2602.15819v1)** | 2026-02-17 |  |
| **[Developing AI Agents with Simulated Data: Why, what, and how?](https://arxiv.org/abs/2602.15816v1)** | 2026-02-17 |  |
| **[Task-Agnostic Continual Learning for Chest Radiograph Classification](https://arxiv.org/abs/2602.15811v1)** | 2026-02-17 | 12 pages, 3 figures |

