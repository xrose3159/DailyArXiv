---
title: Latest 15 Papers - January 15, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## data synthesis
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[RAVEN: Erasing Invisible Watermarks via Novel View Synthesis](https://arxiv.org/abs/2601.08832v1)** | 2026-01-13 | 13 pages |
| **[Motion Attribution for Video Generation](https://arxiv.org/abs/2601.08828v1)** | 2026-01-13 | <details><summary>See t...</summary><p>See the project website at https://research.nvidia.com/labs/sil/projects/MOTIVE/</p></details> |
| **[SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning](https://arxiv.org/abs/2510.22454v2)** | 2026-01-13 | <details><summary>IEEE ...</summary><p>IEEE International Symposium on Biomedical Imaging (ISBI) 2026</p></details> |
| **[A two-step approach to production frontier estimation and the Matsuoka's distribution](https://arxiv.org/abs/2311.06086v3)** | 2026-01-13 | <details><summary>Suple...</summary><p>Suplementary material is presented along with the paper</p></details> |
| **[Reasoning Matters for 3D Visual Grounding](https://arxiv.org/abs/2601.08811v1)** | 2026-01-13 | <details><summary>2025 ...</summary><p>2025 CVPR Workshop on 3D-LLM/VLA: Bridging Language, Vision and Action in 3D Environments</p></details> |
| **[A Vision for Multisensory Intelligence: Sensing, Science, and Synergy](https://arxiv.org/abs/2601.04563v3)** | 2026-01-13 |  |
| **[Aggregating Diverse Cue Experts for AI-Generated Image Detection](https://arxiv.org/abs/2601.08790v1)** | 2026-01-13 | <details><summary>Accep...</summary><p>Accepted by AAAI 2026</p></details> |

## data selection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[3AM: Segment Anything with Geometric Consistency in Videos](https://arxiv.org/abs/2601.08831v1)** | 2026-01-13 | <details><summary>Proje...</summary><p>Project page: https://jayisaking.github.io/3AM-Page/</p></details> |
| **[Motion Attribution for Video Generation](https://arxiv.org/abs/2601.08828v1)** | 2026-01-13 | <details><summary>See t...</summary><p>See the project website at https://research.nvidia.com/labs/sil/projects/MOTIVE/</p></details> |
| **[SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning](https://arxiv.org/abs/2510.22454v2)** | 2026-01-13 | <details><summary>IEEE ...</summary><p>IEEE International Symposium on Biomedical Imaging (ISBI) 2026</p></details> |
| **[A two-step approach to production frontier estimation and the Matsuoka's distribution](https://arxiv.org/abs/2311.06086v3)** | 2026-01-13 | <details><summary>Suple...</summary><p>Suplementary material is presented along with the paper</p></details> |
| **[Reasoning Matters for 3D Visual Grounding](https://arxiv.org/abs/2601.08811v1)** | 2026-01-13 | <details><summary>2025 ...</summary><p>2025 CVPR Workshop on 3D-LLM/VLA: Bridging Language, Vision and Action in 3D Environments</p></details> |
| **[MixServe: An Automatic Distributed Serving System for MoE Models with Hybrid Parallelism Based on Fused Communication Algorithm](https://arxiv.org/abs/2601.08800v1)** | 2026-01-13 | <details><summary>Submi...</summary><p>Submitted to ICDCS 2026</p></details> |
| **[The Conflict Graph Design: Estimating Causal Effects under Arbitrary Neighborhood Interference](https://arxiv.org/abs/2411.10908v3)** | 2026-01-13 |  |

## MLLMs
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[M3CoTBench: Benchmark Chain-of-Thought of MLLMs in Medical Image Understanding](https://arxiv.org/abs/2601.08758v1)** | 2026-01-13 | 40 pages, 8 pages |
| **[MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions](https://arxiv.org/abs/2507.21503v4)** | 2026-01-13 | AAAI2026 Oral |
| **[Incentivizing Cardiologist-Like Reasoning in MLLMs for Interpretable Echocardiographic Diagnosis](https://arxiv.org/abs/2601.08440v1)** | 2026-01-13 |  |
| **[KidVis: Do Multimodal Large Language Models Possess the Visual Perceptual Capabilities of a 6-Year-Old?](https://arxiv.org/abs/2601.08292v1)** | 2026-01-13 |  |
| **[Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback, Diversity-Aware Sampling, and Conflict Regularization](https://arxiv.org/abs/2601.06224v2)** | 2026-01-13 | AAAI-2026 Poster |
| **[GI-Bench: A Panoramic Benchmark Revealing the Knowledge-Experience Dissociation of Multimodal Large Language Models in Gastrointestinal Endoscopy Against Clinical Standards](https://arxiv.org/abs/2601.08183v1)** | 2026-01-13 | <details><summary>45 pa...</summary><p>45 pages, 17 figures, 6 tables. Leaderboard available at: https://roterdl.github.io/GIBench/ . Includes supplementary material</p></details> |
| **[The Agent's First Day: Benchmarking Learning, Exploration, and Scheduling in the Workplace Scenarios](https://arxiv.org/abs/2601.08173v1)** | 2026-01-13 |  |
| **[Where Does Vision Meet Language? Understanding and Refining Visual Fusion in MLLMs via Contrastive Attention](https://arxiv.org/abs/2601.08151v1)** | 2026-01-13 |  |
| **[COSINT-Agent: A Knowledge-Driven Multimodal Agent for Chinese Open Source Intelligence](https://arxiv.org/abs/2503.03215v2)** | 2026-01-13 | <details><summary>This ...</summary><p>This manuscript (arXiv:2503.03215) is being withdrawn at the supervisor's request. The content is preliminary and needs further internal revision and approval before public release. We will resubmit a revised version after completion. Apologies for the inconvenience</p></details> |
| **[PRISM: Self-Pruning Intrinsic Selection Method for Training-Free Multimodal Data Selection](https://arxiv.org/abs/2502.12119v3)** | 2026-01-13 |  |

## data curation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Motion Attribution for Video Generation](https://arxiv.org/abs/2601.08828v1)** | 2026-01-13 | <details><summary>See t...</summary><p>See the project website at https://research.nvidia.com/labs/sil/projects/MOTIVE/</p></details> |
| **[SemiETPicker: Fast and Label-Efficient Particle Picking for CryoET Tomography Using Semi-Supervised Learning](https://arxiv.org/abs/2510.22454v2)** | 2026-01-13 | <details><summary>IEEE ...</summary><p>IEEE International Symposium on Biomedical Imaging (ISBI) 2026</p></details> |
| **[A two-step approach to production frontier estimation and the Matsuoka's distribution](https://arxiv.org/abs/2311.06086v3)** | 2026-01-13 | <details><summary>Suple...</summary><p>Suplementary material is presented along with the paper</p></details> |
| **[FilmSceneDesigner: Chaining Set Design for Procedural Film Scene Generation](https://arxiv.org/abs/2511.19137v2)** | 2026-01-13 |  |
| **[Reasoning Matters for 3D Visual Grounding](https://arxiv.org/abs/2601.08811v1)** | 2026-01-13 | <details><summary>2025 ...</summary><p>2025 CVPR Workshop on 3D-LLM/VLA: Bridging Language, Vision and Action in 3D Environments</p></details> |
| **[On the use of graph models to achieve individual and group fairness](https://arxiv.org/abs/2601.08784v1)** | 2026-01-13 | 75 pages, 46 figures |

