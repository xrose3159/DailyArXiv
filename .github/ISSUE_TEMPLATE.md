---
title: Latest 15 Papers - February 04, 2026
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## data synthesis
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495v1)** | 2026-02-02 | 27 pages |
| **[MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training](https://arxiv.org/abs/2602.02494v1)** | 2026-02-02 | <details><summary>19 pa...</summary><p>19 pages, 8 figures, 5 tables</p></details> |
| **[New explanations and inference for least angle regression](https://arxiv.org/abs/2602.02491v1)** | 2026-02-02 | 50 pages, 9 figures |
| **[Secure Multi-User Linearly-Separable Distributed Computing](https://arxiv.org/abs/2602.02489v1)** | 2026-02-02 |  |
| **[DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726v6)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to ICLR 2026. Project page: https://attention-is-all-i-need.github.io/Design-Logic-Reasoning</p></details> |
| **[Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249v2)** | 2026-02-02 | <details><summary>27 pa...</summary><p>27 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio</p></details> |
| **[HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](https://arxiv.org/abs/2602.02473v1)** | 2026-02-02 |  |

## data selection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495v1)** | 2026-02-02 | 27 pages |
| **[MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training](https://arxiv.org/abs/2602.02494v1)** | 2026-02-02 | <details><summary>19 pa...</summary><p>19 pages, 8 figures, 5 tables</p></details> |
| **[New explanations and inference for least angle regression](https://arxiv.org/abs/2602.02491v1)** | 2026-02-02 | 50 pages, 9 figures |
| **[Secure Multi-User Linearly-Separable Distributed Computing](https://arxiv.org/abs/2602.02489v1)** | 2026-02-02 |  |
| **[DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726v6)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to ICLR 2026. Project page: https://attention-is-all-i-need.github.io/Design-Logic-Reasoning</p></details> |
| **[Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249v2)** | 2026-02-02 | <details><summary>27 pa...</summary><p>27 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio</p></details> |
| **[MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents](https://arxiv.org/abs/2602.02474v1)** | 2026-02-02 | <details><summary>Code ...</summary><p>Code is available at https://github.com/ViktorAxelsen/MemSkill</p></details> |

## MLLMs
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[MentisOculi: Revealing the Limits of Reasoning with Mental Imagery](https://arxiv.org/abs/2602.02465v1)** | 2026-02-02 | 9 pages, 8 figures |
| **[Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation](https://arxiv.org/abs/2602.02401v1)** | 2026-02-02 |  |
| **[CoT-RVS: Zero-Shot Chain-of-Thought Reasoning Segmentation for Videos](https://arxiv.org/abs/2505.18561v4)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to ICLR 2026. Project page: https://danielshkao.github.io/cot-rvs.html. Code: https://github.com/DanielSHKao/CoT-RVS</p></details> |
| **[Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models](https://arxiv.org/abs/2602.02197v1)** | 2026-02-02 | 10 oages, 3 figures |
| **[Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models](https://arxiv.org/abs/2602.02185v1)** | 2026-02-02 |  |
| **[MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language Models through Activation Steering](https://arxiv.org/abs/2510.04217v3)** | 2026-02-02 |  |
| **[One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation](https://arxiv.org/abs/2602.02033v1)** | 2026-02-02 |  |
| **[SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning](https://arxiv.org/abs/2602.01990v1)** | 2026-02-02 |  |
| **[You Only Forward Once: An Efficient Compositional Judging Paradigm](https://arxiv.org/abs/2511.16600v3)** | 2026-02-02 |  |
| **[Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model](https://arxiv.org/abs/2602.01901v1)** | 2026-02-02 | Accepted by AAAI26 |

## data curation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Reward-free Alignment for Conflicting Objectives](https://arxiv.org/abs/2602.02495v1)** | 2026-02-02 | 27 pages |
| **[MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training](https://arxiv.org/abs/2602.02494v1)** | 2026-02-02 | <details><summary>19 pa...</summary><p>19 pages, 8 figures, 5 tables</p></details> |
| **[New explanations and inference for least angle regression](https://arxiv.org/abs/2602.02491v1)** | 2026-02-02 | 50 pages, 9 figures |
| **[Secure Multi-User Linearly-Separable Distributed Computing](https://arxiv.org/abs/2602.02489v1)** | 2026-02-02 |  |
| **[DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726v6)** | 2026-02-02 | <details><summary>Accep...</summary><p>Accepted to ICLR 2026. Project page: https://attention-is-all-i-need.github.io/Design-Logic-Reasoning</p></details> |
| **[Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment](https://arxiv.org/abs/2601.14249v2)** | 2026-02-02 | <details><summary>27 pa...</summary><p>27 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio</p></details> |
| **[HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](https://arxiv.org/abs/2602.02473v1)** | 2026-02-02 |  |

