---
title: Latest 15 Papers - December 15, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## data synthesis
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space](https://arxiv.org/abs/2512.10959v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project page: https://hf.co/spaces/prs-eth/stereospace_web</p></details> |
| **[Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision](https://arxiv.org/abs/2512.10956v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project Page: https://www.cs.virginia.edu/~tsx4zn/stereowalk/</p></details> |
| **[Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization](https://arxiv.org/abs/2512.10955v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project page: https://snap-research.github.io/omni-attribute</p></details> |
| **[Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953v1)** | 2025-12-11 | Tech report |
| **[Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952v1)** | 2025-12-11 |  |
| **[E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training](https://arxiv.org/abs/2512.10950v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project website: https://qitaozhao.github.io/E-RayZer</p></details> |
| **[Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](https://arxiv.org/abs/2512.10949v1)** | 2025-12-11 | <details><summary>Code ...</summary><p>Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1</p></details> |
| **[Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving](https://arxiv.org/abs/2512.10947v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project Page: https://jiawei-yang.github.io/Flex/</p></details> |
| **[AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation](https://arxiv.org/abs/2512.10943v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project page: https://snap-research.github.io/Video-AlcheMinT/snap-research.github.io/Video-AlcheMinT</p></details> |

## data selection
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision](https://arxiv.org/abs/2512.10956v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project Page: https://www.cs.virginia.edu/~tsx4zn/stereowalk/</p></details> |
| **[Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization](https://arxiv.org/abs/2512.10955v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project page: https://snap-research.github.io/omni-attribute</p></details> |
| **[Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953v1)** | 2025-12-11 | Tech report |
| **[Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952v1)** | 2025-12-11 |  |
| **[E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training](https://arxiv.org/abs/2512.10950v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project website: https://qitaozhao.github.io/E-RayZer</p></details> |
| **[Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](https://arxiv.org/abs/2512.10949v1)** | 2025-12-11 | <details><summary>Code ...</summary><p>Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1</p></details> |
| **[Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving](https://arxiv.org/abs/2512.10947v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project Page: https://jiawei-yang.github.io/Flex/</p></details> |
| **[VL-JEPA: Joint Embedding Predictive Architecture for Vision-language](https://arxiv.org/abs/2512.10942v1)** | 2025-12-11 |  |
| **[Mull-Tokens: Modality-Agnostic Latent Thinking](https://arxiv.org/abs/2512.10941v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project webpage: https://arijitray.com/multimodal_thinking/</p></details> |

## MLLMs
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882v1)** | 2025-12-11 |  |
| **[MMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence](https://arxiv.org/abs/2512.10863v1)** | 2025-12-11 |  |
| **[LoC-Path: Learning to Compress for Pathology Multimodal Large Language Models](https://arxiv.org/abs/2512.05391v2)** | 2025-12-11 | 20 pages |
| **[LDP: Parameter-Efficient Fine-Tuning of Multimodal LLM for Medical Report Generation](https://arxiv.org/abs/2512.10750v1)** | 2025-12-11 | Work in progress |
| **[Architecture Decoupling Is Not All You Need For Unified Multimodal Model](https://arxiv.org/abs/2511.22663v2)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project page: https://zhengdian1.github.io/AIA-project/ Code: https://github.com/zhengdian1/AIA</p></details> |
| **[SpatialScore: Towards Comprehensive Evaluation for Spatial Intelligence](https://arxiv.org/abs/2505.17012v2)** | 2025-12-11 | <details><summary>Techn...</summary><p>Technical Report; Project Page: https://haoningwu3639.github.io/SpatialScore</p></details> |
| **[MokA: Multimodal Low-Rank Adaptation for MLLMs](https://arxiv.org/abs/2506.05191v2)** | 2025-12-11 |  |
| **[Grounding Everything in Tokens for Multimodal Large Language Models](https://arxiv.org/abs/2512.10554v1)** | 2025-12-11 | <details><summary>19 pa...</summary><p>19 pages, 16 figures, 12 Tables</p></details> |
| **[Blink: Dynamic Visual Token Resolution for Enhanced Multimodal Understanding](https://arxiv.org/abs/2512.10548v1)** | 2025-12-11 |  |
| **[Thinking Ahead: Foresight Intelligence in MLLMs and World Models](https://arxiv.org/abs/2511.18735v2)** | 2025-12-11 | 25 pages, 27 figures |

## data curation
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision](https://arxiv.org/abs/2512.10956v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project Page: https://www.cs.virginia.edu/~tsx4zn/stereowalk/</p></details> |
| **[Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization](https://arxiv.org/abs/2512.10955v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project page: https://snap-research.github.io/omni-attribute</p></details> |
| **[Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953v1)** | 2025-12-11 | Tech report |
| **[Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952v1)** | 2025-12-11 |  |
| **[E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training](https://arxiv.org/abs/2512.10950v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project website: https://qitaozhao.github.io/E-RayZer</p></details> |
| **[Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation](https://arxiv.org/abs/2512.10949v1)** | 2025-12-11 | <details><summary>Code ...</summary><p>Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1</p></details> |
| **[Towards Efficient and Effective Multi-Camera Encoding for End-to-End Driving](https://arxiv.org/abs/2512.10947v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project Page: https://jiawei-yang.github.io/Flex/</p></details> |
| **[VL-JEPA: Joint Embedding Predictive Architecture for Vision-language](https://arxiv.org/abs/2512.10942v1)** | 2025-12-11 |  |
| **[Mull-Tokens: Modality-Agnostic Latent Thinking](https://arxiv.org/abs/2512.10941v1)** | 2025-12-11 | <details><summary>Proje...</summary><p>Project webpage: https://arijitray.com/multimodal_thinking/</p></details> |

